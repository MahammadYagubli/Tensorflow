import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv('../mahammad.yagubli/lending_club_loan_two.csv')
df.corr()
sns.scatterplot(x='installment', y='loan_amnt', data=df)
sns.barplot( x='home_ownership', y='loan_amnt', data=df )
df.columns
df['load_repaid']=df['loan_status'].apply(lambda x: '1' if x=='Fully Paid' else '0')
df.drop('loan_status', axis=1) 
len(df)
100*df.isnull().sum()/len(df)
df['emp_title'].value_counts()
df=df.drop('emp_title', axis=1)
sorted(df['emp_length'].dropna().unique())
sorted_list=['< 1 year',  
  '1 year'
 '2 years',
 '3 years',
 '4 years',
 '5 years',
 '6 years',
 '7 years',
 '8 years',
 '9 years',
 '10+ years' 
 ]
sns.countplot(x='emp_length',  data=df, order=sorted_list, hue='load_repaid' )
df=df.drop('title', axis=1)
df['mort_acc'].value_counts()
df.corr()['mort_acc']
needed=df.groupby('total_acc').mean()['mort_acc'] 
def getneedeedvalue(total_acc, mort_acc):
    if(np.isnan(mort_acc)):
        return needed[total_acc]
    else:
        return mort_acc
df['mort_acc']=df.apply(lambda x: getneedeedvalue(x['total_acc'],x['mort_acc']   ),axis=1     )
df.isnull().sum()
df=df.dropna()
def number_getter(value):
    return value[1:3]
df['term']=df['term'].apply(lambda x: number_getter(x))
df['term'].nunique()
df.drop(['verification_status','application_type','initial_list_status'], axis=1)
df.drop('grade', axis=1)
dummies= pd.get_dummies(df['sub_grade'], drop_first=True)
df=pd.concat([df, dummies], axis=1)
dummies= pd.get_dummies(df[['verification_status','application_type','initial_list_status']], drop_first=True)
df=pd.concat([df, dummies], axis=1)
df['home_ownership']=df['home_ownership'].apply(lambda x: 'OTHER' if x=='ANY' else x)
df['home_ownership'].value_counts()
df['address'][1][-5:]
df['zip_code']=df['address'].apply(lambda x: x[-5:])
df['zip_code'].value_counts()
dummies= pd.get_dummies(df['zip_code'], drop_first=True)
df=pd.concat([df, dummies], axis=1)
df=df.drop('zip_code', axis=1)
df=df.drop('issue_d', axis=1)
df=df.drop(['verification_status','application_type','initial_list_status'], axis=1)
df['earliest_cr_line']=df['earliest_cr_line'].apply(lambda x: int(  x[-4:]))
df['earliest_cr_line']
df['term'][1][1:3]
#df=df.drop('emp_title', axis=1)
dummies= pd.get_dummies(df['home_ownership'], drop_first=True)
df=pd.concat([df, dummies], axis=1)
df=df.drop('home_ownership', axis=1)
df['purpose'].value_counts()
dummies= pd.get_dummies(df['purpose'], drop_first=True)
df=pd.concat([df, dummies], axis=1)
df=df.drop('purpose', axis=1)
df['term']=df['term'].apply(lambda x: x[1:3])
#df=df.drop('title', axis=1) 
df['emp_length'].replace(to_replace="4 years",value= "10"  ) 
df=df.drop(['loan_status', 'verification_status_Source Verified', 'verification_status_Verified',
       'application_type_INDIVIDUAL', 'application_type_JOINT',
       'initial_list_status_w', 'grade'], axis=1)
#df=df.drop(['grade'], axis=1)
df=df.drop(['sub_grade'], axis=1)
df['emp_length']=df['emp_length'].replace(to_replace="10+ years",value= 10  ) 
df['emp_length']=df['emp_length'].replace(to_replace="< 1 year",value= 1  ) 
df['emp_length']=df['emp_length'].replace(to_replace="6 years",value= 6  ) 
df['emp_length']=df['emp_length'].replace(to_replace="9 years",value=9 ) 
df['emp_length']=df['emp_length'].replace(to_replace="5 years",value=5 ) 
df['emp_length']=df['emp_length'].replace(to_replace="3 years",value= 3  ) 
df['emp_length']=df['emp_length'].replace(to_replace="2 years",value= 2  ) 
df['emp_length']=df['emp_length'].replace(to_replace="1 year",value=4 ) 
df['emp_length']=df['emp_length'].replace(to_replace="4 years",value= 7  )
df['emp_length']=df['emp_length'].replace(to_replace="7 years",value= 7  ) 
df['emp_length']=df['emp_length'].replace(to_replace="8 years",value= 8  ) 
df=df.drop('address', axis=1)
df['term']=df['term'].astype('int32')
X=df.drop('load_repaid', axis=1)
y=df['load_repaid'].values
X_train, X_test, y_train, y_test = train_test_split(  X, y, test_size=0.2, random_state=101)
from sklearn.preprocessing import MinMaxScaler
scaler= MinMaxScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
model=Sequential()
model.add(Dense(78, activation='relu'))
model.add(Dropout( 0.2))
model.add(Dense(78, activation='relu'))
model.add(Dropout( 0.2))
model.add(Dense(78, activation='relu'))
model.add(Dropout( 0.2))
model.add(Dense(units=1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam')
model.fit(x=X_train, y=y_train, epochs=25, batch_size=256, validation_data=(X_test, y_test) )
