import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv('../Iyoqivino/DATA/cancer_classification.csv')
df.describe().transpose()
sns.countplot(x='benign_0__mal_1', data=df)
df.corr()['benign_0__mal_1'][:-1].sort_values().plot(kind='bar')
plt.figure(figsize=(12,12))
sns.heatmap(df.corr() )
X=df.drop('benign_0__mal_1', axis=1).values
y=df['benign_0__mal_1'].values
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)
from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.transform(X_test)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
#creating model to check our precision 
model=Sequential()
model.add(Dense(30, activation='relu'))
model.add(Dense(30, activation='relu'))
#Binary classification
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam')
model.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_test, y_test))
loses=pd.DataFrame(model.history.history)
loses.plot()


model=Sequential()
model.add(Dense(30, activation='relu'))
model.add(Dense(15, activation='relu'))
#Binary classification
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam')
model.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_test, y_test))
loses=pd.DataFrame(model.history.history)
loses.plot()
#Early stopping means  we are going to avoid over fitting and training 
from tensorflow.keras.callbacks import EarlyStopping
#help(EarlyStopping)
early_stop=EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)
model=Sequential()
model.add(Dense(30, activation='relu'))
#dropout means each time we are going to randomly to turn of the neurons to get the better p[recisions and model]
model.add(Dropout(0.5))
model.add(Dense(15, activation='relu'))
model.add(Dropout(0.5))
#Binary classification
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam')
model.fit(x=X_train, y=y_train, epochs=600, validation_data=(X_test, y_test), callbacks=[early_stop])
loses=pd.DataFrame(model.history.history)
loses.plot()
y_pred = model.predict(X_test)
y_pred = np.round(y_pred).astype(int)
from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test, y_pred))
